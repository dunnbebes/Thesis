{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "from util.util_load         import read_txt, read_scenario\n",
    "from env_action.metaheu     import GeneticAlgorithm, random_population\n",
    "from env_action.environment import FJSP_under_uncertainties_Env\n",
    "from env_action.data_indentifier import InstanceData, ScenarioData\n",
    "\n",
    "directory           = 'SMALL'\n",
    "planning_horizon    = 480*60\n",
    "critical_machines   = {5, 6, 7, 8, 9, 10, 11, 12, 13, 21, 22, 26, 27}\n",
    "ReworkProbability   = 0.03\n",
    "maxtime             = 10\n",
    "PopSize             = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env     import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks   import BaseCallback, EvalCallback\n",
    "from stable_baselines3.common.monitor     import Monitor\n",
    "from stable_baselines3.common.env_checker import check_env \n",
    "\n",
    "WeibullDistribution = pd.read_excel('DATA/DataMaster.xlsx', sheet_name='Distribution')\n",
    "K    = 30\n",
    "with open('pickle_instances_480.pkl', 'rb') as f:\n",
    "    instances = pickle.load(f)\n",
    "with open('pickle_scenarios_480.pkl', 'rb') as f:\n",
    "    scenarios = pickle.load(f)\n",
    "env1 = FJSP_under_uncertainties_Env(True , True , instances, scenarios, K, WeibullDistribution, critical_machines, ReworkProbability, planning_horizon, PopSize, maxtime)\n",
    "env2 = FJSP_under_uncertainties_Env(True , False, instances, scenarios, K, WeibullDistribution, critical_machines, ReworkProbability, planning_horizon, PopSize, maxtime)\n",
    "env3 = FJSP_under_uncertainties_Env(False, False, instances, scenarios, K, WeibullDistribution, critical_machines, ReworkProbability, planning_horizon, PopSize, maxtime)\n",
    "\n",
    "# env = FJSP_under_uncertainties_Env(J, I, K, X_ijk, S_ij, C_ij, C_j, p_ijk, d_j, n_j, MC_ji, n_MC_ji, h_ijk, OperationPool, JA_event, MB_event, PopSize, maxtime)\n",
    "\n",
    "# check_env(env1)\n",
    "# obs = env1.reset(seed=42)\n",
    "# print(\"Observation:\", obs)\n",
    "\n",
    "# episodes = 10\n",
    "# for episode in range(episodes):\n",
    "# \tdone = False\n",
    "# \tobs = env.reset()\n",
    "# \twhile done == False:#not done:\n",
    "# \t\trandom_action = env.action_space.sample()\n",
    "# \t\tobs, reward, done, truncated, info = env.step(random_action)\n",
    "# \t\tprint('reward', reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to logs/DQN-2024-06-26_01-49-21\\DQN_phase1_0\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 0, 'TS': 0, 'LFOH': 0, 'LAPH': 0, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 0, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 0, 'CDR5': 0, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH, Action counts: {'GA': 0, 'TS': 0, 'LFOH': 0, 'LAPH': 1, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 0, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 0, 'CDR5': 0, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR5, Action counts: {'GA': 0, 'TS': 0, 'LFOH': 0, 'LAPH': 1, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 0, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 0, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_TS, Action counts: {'GA': 0, 'TS': 0, 'LFOH': 0, 'LAPH': 1, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 1, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 0, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [350, 340, 206, 81, 352, 342, 80, 207, 355, 344, 206, 83, 357, 346, 82, 207, 359, 349, 85, 83, 351, 362, 82, 84, 365, 353, 356, 86, 85, 367, 73, 84, 358, 369, 371, 361, 86, 90, 364, 373, 73, 89, 366, 378, 90, 211, 368, 381, 212, 89, 384, 370, 211, 91, 387, 372, 88, 212, 389, 375, 91, 93, 379, 391, 92, 88, 393, 382, 96, 385, 93, 396, 399, 95, 92, 388, 401, 390, 96, 98, 403, 392, 97, 95, 394, 405, 100, 98, 408, 397, 99, 97, 400, 411, 102, 100, 415, 402, 101, 99, 417, 404, 102, 104, 419, 407, 101, 103, 421, 410, 643, 104, 423, 414, 105, 416, 103, 425, 418, 428, 106, 643, 431, 420, 107, 105, 422, 433, 106, 108, 435, 424, 109, 107, 427, 440, 108, 110, 430, 442, 109, 111, 445, 432, 112, 110, 434, 447, 94, 111, 450, 439, 113, 456, 112, 441, 459, 444, 94, 114, 446, 462, 113, 115, 448, 465, 117, 114, 468, 454, 118, 115, 457, 471, 119, 117, 473, 460, 120, 118, 464, 475, 121, 119, 477, 467, 122, 120, 470, 479, 121, 123, 481, 472, 124, 483, 122, 474, 476, 125, 123, 485, 488, 478, 124, 126, 480, 490, 125, 127, 482, 492, 128, 126, 496, 484, 129, 127, 499, 486, 130, 128, 489, 642, 131, 129, 491, 215, 130, 132, 493, 131, 133, 497, 640, 132, 134, 133, 214, 217, 116, 215, 135, 134, 116, 136, 135, 137, 217, 214, 220, 216, 139, 136, 140, 137, 141, 139, 140, 142, 220, 219, 222, 216, 141, 143, 144, 142, 145, 143, 219, 221, 224, 222, 146, 144, 147, 145, 148, 146, 147, 149, 224, 221, 226, 225, 150, 148, 149, 151, 152, 150, 153, 151, 223, 228, 225, 154, 152, 153, 155, 154, 156, 223, 228, 231, 232, 155, 138, 226, 157, 156, 158, 138, 157, 159, 235, 234, 232, 231, 158, 161, 162, 159, 163, 161, 234, 162, 235, 164, 237, 236, 163, 165, 164, 166, 167, 165, 244, 237, 236, 240, 166, 168, 167, 169, 168, 170, 171, 169, 240, 245, 244, 246, 170, 172, 171, 173, 175, 172, 245, 177, 250, 246, 247, 173, 178, 175, 177, 179, 178, 180, 251, 247, 261, 250, 179, 160, 181, 180, 160, 182, 183, 181, 262, 251, 261, 264, 185, 182, 183, 186, 187, 185, 264, 269, 262, 265, 188, 186, 187, 190, 191, 188, 190, 192, 269, 265, 270, 274, 193, 191, 192, 194, 193, 195, 196, 194, 275, 274, 280, 270, 195, 197, 198, 196, 199, 197, 281, 284, 280, 275, 200, 198, 199, 201, 202, 200, 201, 203, 284, 286, 285, 281, 184, 202, 203, 208, 184, 209, 208, 287, 286, 285, 210, 279, 227, 209, 210, 229, 230, 227, 288, 279, 287, 294, 229, 233, 230, 238, 239, 233, 248, 238, 288, 291, 294, 295, 252, 239, 255, 248, 257, 252, 291, 255, 295, 260, 292, 290, 263, 257, 266, 260, 263, 272, 296, 299, 290, 292, 70, 266, 272, 213, 70, 276, 213, 277, 296, 299, 297, 241, 276, 278, 282, 277, 278, 215, 241, 273, 271, 297, 289, 282, 215, 283, 289, 214, 283, 217, 267, 268, 273, 214, 298, 271, 293, 217, 298, 216, 220, 293, 258, 259, 268, 267, 68, 216, 220, 69, 219, 68, 256, 259, 258, 243, 69, 222, 66, 219, 222, 67, 66, 221, 253, 242, 243, 256, 67, 224, 64, 221, 65, 224, 223, 253, 242, 249, 64, 65, 226, 62, 223, 63, 226, 254, 249, 225, 62, 63, 231, 49, 225, 61, 231, 254, 228, 49, 234, 61, 59, 228, 60, 234, 59, 232, 60, 236, 232, 57, 236, 58, 50, 57, 235, 58, 237, 50, 240, 235, 54, 56, 240, 244, 237, 56, 245, 52, 54, 245, 55, 246, 244, 247, 55, 593, 52, 53, 247, 246, 251, 53, 262, 51, 593, 251, 595, 250, 51, 262, 594, 250, 595, 265, 594, 261, 597, 596, 261, 265, 597, 270, 599, 596, 264, 264, 598, 270, 599, 275, 601, 269, 598, 269, 600, 275, 281, 601, 274, 600, 607, 274, 606, 281, 285, 607, 280, 606, 609, 280, 608, 285, 609, 287, 612, 608, 284, 284, 611, 287, 612, 288, 619, 286, 611, 618, 286, 288, 295, 619, 621, 618, 279, 279, 620, 295, 621, 292, 625, 620, 294, 294, 624, 292, 296, 625, 629, 291, 624, 291, 628, 296, 241, 629, 290, 628, 633, 290, 632, 241, 273, 633, 603, 632, 299, 299, 602, 273, 268, 603, 602, 297, 605, 297, 604, 268, 259, 605, 271, 604, 613, 271, 610, 259, 256, 613, 610, 615, 267, 614, 267, 256, 615, 242, 614, 249, 258, 249, 258, 243, 254, 242, 243, 253, 617, 254, 253, 616, 623, 617, 616, 622, 627, 623, 622, 626, 631, 627, 626, 630, 635, 631, 630, 634, 637, 635, 634, 636, 639, 637, 636, 638, 639, 638, 641, 641, 644, 644, 644, 644, 644]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 1, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 1, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 0, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_TS, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 1, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 2, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 0, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 2, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 2, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 0, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 2, 'LAP_LFO': 0, 'LFOH_TS': 0, 'LAPH_TS': 2, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 2, 'LAP_LFO': 0, 'LFOH_TS': 1, 'LAPH_TS': 2, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 1, 'LAPH_TS': 2, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 0, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_GA, Action counts: {'GA': 0, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 1, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: GA, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 1, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 1, 'CDR6': 1, 'RCRS': 0}\n",
      "-------------------------------------------------\n",
      "Method selection:                    RCRS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: RCRS, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 1, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 1, 'CDR6': 1, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR5, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 1, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 2, 'CDR6': 1, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR5, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 1, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 3, 'CDR6': 1, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 1, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 3, 'CDR6': 2, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_GA, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 0, 'CDR4': 1, 'CDR5': 3, 'CDR6': 2, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 3, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 1, 'CDR5': 3, 'CDR6': 2, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 4, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 1, 'CDR5': 3, 'CDR6': 2, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 4, 'LAP_LFO': 0, 'LFOH_TS': 2, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 3, 'CDR6': 2, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 4, 'LAP_LFO': 0, 'LFOH_TS': 3, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 3, 'CDR6': 2, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 4, 'LAP_LFO': 0, 'LFOH_TS': 3, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 3, 'CDR6': 3, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 3, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 3, 'CDR6': 3, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 1, 'TS': 1, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 3, 'CDR6': 3, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [343, 356, 28, 638, 17, 16, 358, 344, 345, 361, 29, 20, 364, 348, 18, 17, 372, 350, 34, 349, 19, 379, 18, 22, 351, 384, 40, 28, 352, 382, 641, 21, 22, 23, 388, 357, 34, 41, 394, 359, 23, 24, 400, 362, 402, 43, 365, 405, 366, 24, 25, 407, 367, 44, 368, 414, 26, 25, 369, 417, 46, 416, 370, 26, 27, 418, 371, 47, 46, 373, 421, 27, 35, 420, 375, 48, 378, 422, 29, 38, 35, 381, 430, 385, 50, 432, 40, 42, 387, 38, 439, 389, 444, 50, 58, 41, 43, 390, 450, 45, 448, 391, 42, 60, 392, 457, 45, 49, 44, 393, 460, 61, 60, 464, 396, 47, 51, 48, 472, 397, 70, 399, 476, 49, 52, 401, 478, 51, 482, 76, 403, 486, 53, 404, 52, 491, 408, 78, 499, 410, 54, 53, 411, 497, 85, 415, 185, 54, 55, 419, 86, 423, 55, 56, 424, 89, 425, 196, 185, 58, 57, 56, 427, 428, 92, 59, 431, 57, 433, 195, 102, 434, 62, 59, 435, 107, 440, 61, 63, 62, 441, 197, 108, 442, 78, 64, 63, 445, 109, 446, 64, 65, 447, 199, 197, 454, 111, 66, 456, 65, 459, 113, 199, 205, 462, 66, 67, 465, 115, 468, 67, 68, 467, 116, 204, 470, 69, 68, 205, 471, 118, 473, 70, 71, 69, 474, 215, 123, 475, 477, 71, 72, 479, 126, 480, 73, 72, 481, 214, 215, 134, 483, 73, 74, 484, 145, 485, 75, 74, 488, 219, 147, 489, 77, 75, 490, 149, 492, 76, 79, 493, 221, 496, 150, 77, 187, 80, 79, 151, 222, 81, 80, 152, 188, 187, 82, 81, 153, 231, 83, 82, 190, 188, 158, 86, 84, 83, 228, 159, 85, 84, 88, 192, 190, 161, 89, 90, 88, 232, 166, 91, 90, 193, 192, 195, 169, 92, 93, 91, 235, 171, 94, 93, 198, 193, 173, 237, 95, 94, 175, 202, 198, 95, 96, 196, 180, 240, 97, 96, 186, 206, 97, 204, 98, 243, 194, 99, 98, 207, 206, 203, 102, 99, 100, 245, 210, 202, 108, 101, 100, 207, 212, 230, 101, 103, 247, 248, 104, 103, 211, 222, 260, 105, 254, 104, 276, 212, 216, 211, 106, 105, 277, 259, 107, 106, 110, 282, 216, 217, 109, 112, 110, 598, 262, 111, 112, 114, 220, 221, 217, 113, 116, 214, 117, 114, 265, 115, 118, 600, 119, 117, 223, 220, 219, 120, 119, 268, 120, 121, 224, 606, 228, 123, 121, 122, 270, 122, 124, 225, 224, 223, 232, 274, 607, 125, 124, 225, 226, 127, 125, 273, 126, 128, 127, 611, 234, 226, 129, 128, 231, 279, 130, 129, 236, 234, 237, 614, 130, 131, 275, 131, 132, 241, 235, 133, 132, 281, 275, 618, 259, 134, 133, 135, 242, 240, 241, 136, 280, 135, 621, 244, 242, 136, 137, 236, 286, 137, 138, 246, 138, 139, 623, 243, 288, 286, 139, 140, 249, 254, 141, 140, 294, 244, 625, 142, 141, 249, 250, 142, 143, 296, 246, 145, 143, 144, 627, 251, 147, 268, 144, 146, 296, 151, 149, 146, 148, 253, 270, 633, 150, 148, 154, 153, 245, 256, 152, 155, 158, 154, 274, 155, 639, 156, 159, 258, 156, 157, 161, 157, 160, 261, 183, 258, 247, 160, 162, 635, 162, 163, 261, 264, 169, 164, 163, 171, 636, 165, 164, 267, 173, 250, 165, 167, 166, 269, 267, 168, 167, 262, 641, 170, 168, 271, 170, 172, 251, 188, 172, 177, 284, 271, 175, 190, 279, 178, 269, 177, 193, 179, 178, 285, 180, 186, 196, 181, 179, 253, 199, 184, 181, 287, 281, 202, 280, 191, 184, 273, 194, 205, 290, 200, 191, 206, 200, 201, 256, 292, 212, 290, 203, 208, 201, 284, 216, 209, 208, 287, 291, 292, 231, 213, 209, 236, 210, 227, 213, 295, 291, 264, 237, 229, 227, 285, 241, 230, 229, 233, 297, 295, 248, 243, 233, 238, 260, 245, 239, 238, 299, 265, 247, 239, 252, 294, 250, 640, 252, 255, 299, 642, 253, 257, 255, 256, 257, 263, 288, 259, 266, 263, 297, 282, 262, 266, 272, 265, 276, 272, 278, 268, 277, 278, 283, 270, 289, 283, 273, 293, 289, 275, 293, 298, 280, 298, 593, 284, 286, 593, 594, 288, 291, 294, 594, 595, 296, 299, 596, 595, 596, 597, 600, 599, 597, 598, 601, 599, 602, 601, 602, 603, 603, 604, 604, 605, 614, 605, 608, 606, 609, 608, 607, 610, 609, 612, 610, 611, 613, 612, 613, 615, 615, 616, 618, 616, 617, 623, 619, 617, 627, 621, 620, 625, 620, 622, 622, 624, 624, 626, 626, 628, 628, 629, 630, 629, 631, 630, 631, 632, 633, 632, 637, 182, 637, 182, 634, 183, 639, 638, 635, 634, 636, 638, 185, 188, 187, 185, 641, 192, 187, 195, 192, 190, 196, 197, 195, 193, 197, 198, 199, 204, 198, 202, 207, 204, 205, 206, 211, 207, 211, 214, 212, 215, 214, 216, 217, 215, 219, 217, 219, 220, 220, 221, 221, 222, 223, 222, 223, 224, 224, 225, 231, 226, 225, 226, 228, 236, 232, 228, 234, 232, 619, 235, 234, 240, 235, 240, 242, 237, 242, 244, 241, 243, 246, 244, 245, 246, 249, 247, 251, 249, 250, 254, 251, 253, 256, 258, 254, 259, 258, 261, 262, 261, 264, 265, 267, 264, 268, 269, 267, 270, 273, 271, 269, 275, 274, 271, 280, 274, 279, 284, 281, 279, 286, 285, 281, 288, 291, 287, 285, 294, 290, 287, 296, 290, 292, 299, 295, 292, 295, 297, 297, 643, 643]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 3, 'CDR6': 3, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 3, 'CDR6': 4, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR5, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 0, 'CDR3': 1, 'CDR4': 2, 'CDR5': 4, 'CDR6': 4, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR2\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR2, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 1, 'CDR3': 1, 'CDR4': 2, 'CDR5': 4, 'CDR6': 4, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR2\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR2, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 2, 'CDR3': 1, 'CDR4': 2, 'CDR5': 4, 'CDR6': 4, 'RCRS': 1}\n",
      "-------------------------------------------------\n",
      "Method selection:                    RCRS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: RCRS, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 2, 'CDR3': 1, 'CDR4': 2, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR2\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR2, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 3, 'CDR3': 1, 'CDR4': 2, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 4, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 3, 'CDR3': 1, 'CDR4': 3, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 3, 'CDR3': 1, 'CDR4': 3, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 0, 'CDR2': 3, 'CDR3': 1, 'CDR4': 4, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR1\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR1, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 0, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 4, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_GA, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 1, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 4, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 1, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 5, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 1, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 6, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 1, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 4, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR5, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 0, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 1, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 5, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAP_LFO\n",
      "Step reward: -0.0035729166120290756, Total episode reward: -0.0035729166120290756\n",
      "Action taken: LAP_LFO, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 1, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 5, 'CDR6': 4, 'RCRS': 2}\n",
      "-------------------------------------------------\n",
      "Method selection:                    RCRS\n",
      "Step reward: -0.0035729166120290756, Total episode reward: -0.007145833224058151\n",
      "Action taken: RCRS, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 1, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 5, 'CDR6': 4, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-GA\n",
      "Step reward: -0.20729166269302368, Total episode reward: -0.21443749591708183\n",
      "Action taken: LAPH_GA, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 2, 'CDR1': 1, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 5, 'CDR6': 4, 'RCRS': 3}\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11       |\n",
      "|    ep_rew_mean      | -0.0536  |\n",
      "|    exploration_rate | 0.615    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 0        |\n",
      "|    time_elapsed     | 82       |\n",
      "|    total_timesteps  | 44       |\n",
      "| train/              |          |\n",
      "|    actual_tardiness | 0        |\n",
      "|    episode_reward   | 0        |\n",
      "----------------------------------\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR1\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR1, Action counts: {'GA': 1, 'TS': 2, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 2, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 5, 'CDR6': 4, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [48, 54, 56, 47, 49, 533, 539, 156, 154, 213, 48, 541, 50, 535, 49, 57, 55, 51, 58, 161, 56, 162, 50, 52, 229, 227, 51, 167, 230, 164, 57, 52, 59, 53, 58, 60, 54, 539, 543, 173, 233, 168, 53, 541, 544, 62, 59, 54, 55, 60, 63, 56, 179, 181, 55, 252, 239, 65, 62, 56, 57, 255, 188, 67, 63, 192, 58, 546, 543, 57, 549, 544, 257, 65, 58, 198, 68, 195, 59, 67, 69, 60, 61, 59, 204, 207, 266, 68, 60, 276, 70, 62, 69, 71, 61, 278, 63, 212, 214, 556, 546, 64, 62, 549, 558, 63, 70, 72, 282, 65, 216, 71, 215, 73, 64, 66, 65, 67, 66, 72, 219, 223, 74, 68, 289, 283, 76, 73, 67, 69, 298, 561, 556, 226, 225, 68, 558, 562, 74, 69, 77, 70, 76, 78, 71, 234, 231, 70, 79, 77, 71, 72, 81, 78, 236, 240, 73, 561, 564, 72, 79, 245, 251, 565, 75, 73, 83, 562, 74, 84, 81, 75, 76, 253, 74, 254, 83, 85, 76, 77, 84, 88, 78, 258, 259, 566, 77, 564, 90, 80, 78, 85, 565, 567, 79, 265, 269, 88, 91, 80, 81, 79, 82, 90, 92, 275, 279, 81, 83, 93, 91, 82, 84, 83, 281, 86, 286, 566, 570, 92, 94, 84, 567, 571, 85, 93, 95, 86, 88, 291, 292, 89, 85, 94, 97, 88, 90, 95, 98, 294, 295, 89, 91, 90, 570, 572, 100, 91, 297, 299, 97, 571, 573, 92, 103, 98, 93, 92, 100, 93, 104, 94, 103, 105, 95, 94, 96, 574, 572, 106, 104, 95, 576, 97, 573, 107, 105, 96, 98, 97, 99, 108, 106, 98, 100, 107, 109, 99, 101, 102, 100, 103, 101, 577, 574, 108, 110, 578, 111, 576, 109, 104, 102, 103, 105, 104, 105, 114, 110, 106, 115, 111, 107, 106, 107, 116, 580, 114, 577, 108, 117, 115, 578, 582, 109, 108, 109, 116, 118, 110, 119, 117, 111, 110, 112, 111, 118, 113, 120, 584, 580, 119, 121, 114, 112, 586, 582, 113, 115, 114, 122, 120, 115, 116, 125, 121, 117, 116, 122, 126, 117, 584, 588, 118, 127, 125, 592, 586, 119, 118, 128, 126, 119, 120, 127, 129, 121, 120, 128, 121, 130, 123, 595, 588, 122, 131, 129, 598, 592, 124, 123, 125, 122, 132, 130, 124, 126, 133, 131, 125, 127, 126, 127, 132, 134, 595, 599, 128, 133, 135, 129, 598, 600, 128, 136, 134, 129, 130, 137, 135, 131, 130, 131, 138, 136, 132, 599, 602, 139, 137, 133, 603, 600, 132, 140, 133, 138, 134, 141, 139, 135, 134, 142, 140, 135, 136, 145, 141, 604, 602, 137, 603, 607, 136, 146, 137, 142, 138, 147, 145, 139, 138, 139, 148, 146, 140, 149, 147, 609, 604, 141, 607, 610, 140, 141, 148, 153, 143, 142, 154, 149, 144, 143, 145, 142, 153, 155, 144, 146, 154, 156, 145, 611, 609, 147, 616, 610, 146, 147, 155, 158, 148, 159, 156, 149, 150, 148, 160, 149, 151, 158, 159, 161, 150, 152, 611, 618, 151, 153, 616, 621, 152, 154, 162, 160, 153, 155, 161, 164, 154, 156, 157, 155, 156, 167, 162, 158, 168, 164, 157, 159, 618, 625, 158, 621, 626, 169, 167, 159, 160, 170, 168, 161, 160, 169, 172, 161, 163, 162, 170, 173, 630, 625, 163, 164, 165, 162, 631, 626, 174, 172, 166, 164, 173, 176, 167, 165, 168, 166, 167, 174, 179, 169, 168, 176, 181, 170, 632, 630, 171, 169, 633, 631, 170, 179, 182, 172, 183, 181, 171, 173, 175, 172, 173, 182, 185, 174, 183, 187, 175, 176, 632, 634, 218, 174, 177, 635, 633, 188, 178, 176, 185, 187, 190, 179, 177, 178, 180, 179, 181, 188, 192, 180, 182, 190, 193, 181, 183, 636, 634, 184, 182, 192, 195, 635, 638, 183, 185, 196, 193, 184, 186, 187, 185, 186, 197, 195, 188, 196, 198, 187, 190, 636, 191, 188, 199, 190, 197, 638, 192, 202, 198, 191, 193, 194, 192, 193, 204, 199, 195, 205, 202, 194, 196, 195, 196, 206, 204, 197, 207, 205, 198, 197, 198, 211, 206, 200, 199, 212, 207, 201, 200, 199, 202, 211, 214, 203, 201, 215, 212, 204, 202, 203, 205, 204, 214, 216, 206, 205, 217, 215, 207, 208, 206, 219, 209, 207, 216, 220, 217, 210, 208, 211, 209, 212, 210, 221, 219, 213, 211, 222, 220, 214, 212, 213, 215, 214, 221, 223, 215, 216, 222, 224, 217, 216, 223, 225, 217, 219, 226, 224, 220, 219, 228, 220, 225, 221, 231, 226, 222, 221, 222, 232, 228, 223, 231, 234, 224, 223, 224, 235, 232, 225, 236, 234, 226, 225, 227, 226, 237, 235, 228, 236, 240, 227, 229, 230, 228, 231, 229, 241, 237, 240, 242, 232, 230, 231, 233, 232, 234, 233, 243, 241, 235, 242, 244, 234, 236, 235, 243, 245, 238, 236, 237, 246, 244, 239, 238, 237, 240, 245, 247, 239, 241, 246, 249, 240, 242, 241, 242, 250, 247, 243, 249, 251, 244, 243, 253, 250, 244, 245, 251, 254, 246, 245, 253, 256, 248, 246, 247, 258, 254, 249, 248, 247, 259, 256, 249, 250, 258, 261, 251, 252, 250, 262, 259, 251, 253, 264, 261, 252, 254, 253, 255, 254, 265, 262, 256, 267, 264, 255, 257, 256, 258, 257, 268, 265, 259, 269, 267, 260, 258, 261, 259, 260, 270, 268, 262, 269, 271, 261, 263, 264, 262, 263, 270, 273, 265, 271, 274, 264, 266, 267, 265, 266, 273, 275, 268, 279, 274, 267, 269, 268, 280, 269, 275, 270, 281, 279, 271, 270, 272, 271, 280, 284, 273, 285, 281, 272, 274, 273, 276, 274, 286, 284, 275, 287, 285, 277, 276, 587, 278, 275, 279, 277, 288, 286, 290, 287, 280, 278, 279, 281, 280, 282, 291, 288, 283, 281, 292, 290, 284, 282, 285, 283, 284, 294, 291, 285, 286, 292, 295, 287, 286, 296, 294, 287, 289, 288, 297, 295, 289, 290, 288, 299, 296, 290, 291, 297, 301, 292, 302, 293, 291, 303, 304, 305, 299, 292, 294, 307, 306, 293, 295, 310, 309, 312, 311, 294, 313, 315, 295, 296, 316, 317, 297, 319, 318, 298, 322, 296, 321, 297, 325, 323, 299, 326, 328, 500, 298, 330, 329, 299, 331, 332, 501, 333, 334, 335, 336, 339, 337, 500, 502, 340, 341, 342, 343, 501, 503, 345, 344, 348, 346, 350, 349, 351, 504, 502, 352, 355, 353, 505, 503, 356, 357, 358, 359, 361, 362, 365, 364, 504, 506, 366, 367, 369, 368, 505, 507, 370, 371, 372, 373, 375, 378, 508, 506, 381, 379, 384, 382, 507, 509, 385, 387, 388, 389, 391, 390, 392, 393, 510, 508, 394, 396, 397, 399, 509, 511, 401, 400, 403, 402, 405, 404, 512, 510, 408, 407, 410, 411, 513, 511, 415, 414, 417, 416, 419, 418, 514, 512, 420, 421, 423, 422, 515, 513, 425, 424, 427, 428, 430, 431, 432, 433, 514, 516, 434, 435, 439, 440, 515, 517, 441, 442, 445, 444, 446, 447, 516, 518, 448, 450, 456, 454, 519, 517, 459, 457, 462, 460, 465, 464, 468, 467, 520, 518, 470, 471, 521, 473, 472, 519, 475, 474, 476, 477, 478, 479, 520, 522, 481, 480, 483, 482, 523, 521, 485, 484, 488, 486, 489, 490, 492, 522, 491, 524, 493, 496, 523, 525, 497, 499, 640, 524, 526, 527, 525, 528, 526, 527, 529, 530, 528, 531, 529, 530, 532, 531, 533, 534, 532, 535, 533, 536, 534, 537, 535, 538, 536, 537, 539, 540, 538, 541, 539, 540, 542, 543, 541, 544, 542, 543, 545, 544, 546, 545, 547, 548, 546, 549, 547, 548, 550, 551, 549, 552, 550, 551, 553, 554, 552, 555, 553, 554, 556, 557, 555, 558, 556, 557, 559, 558, 560, 559, 561, 560, 562, 561, 563, 564, 562, 565, 563, 566, 564, 567, 565, 568, 566, 569, 567, 570, 568, 569, 571, 570, 572, 571, 573, 572, 574, 575, 573, 574, 576, 575, 577, 576, 578, 579, 577, 578, 580, 579, 581, 582, 580, 581, 583, 584, 582, 585, 583, 584, 586, 588, 585, 586, 589, 588, 590, 589, 591, 592, 590, 591, 593, 592, 594, 593, 595, 594, 596, 595, 597, 596, 598, 597, 599, 600, 598, 599, 601, 602, 600, 603, 601, 602, 604, 603, 605, 604, 606, 605, 607, 606, 608, 607, 609, 608, 610, 609, 611, 610, 612, 611, 613, 614, 612, 613, 615, 614, 616, 617, 615, 616, 618, 617, 619, 620, 618, 619, 621, 620, 622, 623, 621, 624, 622, 625, 623, 626, 624, 627, 625, 626, 628, 627, 629, 628, 630, 629, 631, 632, 630, 633, 631, 634, 632, 635, 633, 636, 634, 637, 635, 638, 636, 637, 639, 638, 639, 641, 641, 641, 641, 641]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 1, 'TS': 3, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 2, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 5, 'CDR6': 4, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_GA, Action counts: {'GA': 1, 'TS': 3, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 3, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 5, 'CDR6': 4, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR5, Action counts: {'GA': 1, 'TS': 3, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 3, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 4, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 1, 'TS': 3, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 3, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 5, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 1, 'TS': 3, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 3, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [336, 335, 611, 609, 610, 612, 339, 337, 341, 340, 342, 343, 344, 345, 346, 348, 349, 611, 613, 350, 614, 612, 352, 351, 355, 353, 356, 357, 358, 359, 361, 362, 613, 615, 616, 614, 364, 365, 367, 366, 369, 368, 370, 371, 372, 373, 617, 615, 375, 378, 618, 616, 381, 379, 382, 384, 385, 387, 388, 389, 390, 391, 619, 617, 620, 618, 393, 392, 396, 394, 399, 397, 401, 400, 403, 402, 621, 619, 620, 622, 404, 405, 408, 407, 411, 410, 415, 414, 417, 416, 419, 418, 621, 623, 624, 622, 421, 420, 422, 423, 424, 425, 427, 428, 431, 430, 623, 625, 624, 626, 432, 433, 434, 435, 439, 440, 441, 442, 444, 445, 627, 625, 446, 447, 628, 626, 450, 448, 454, 456, 459, 457, 460, 462, 465, 464, 627, 629, 628, 630, 467, 468, 470, 471, 472, 473, 475, 474, 476, 477, 631, 629, 478, 479, 632, 630, 480, 481, 482, 483, 484, 485, 486, 488, 489, 490, 633, 631, 634, 632, 492, 491, 496, 493, 497, 499, 642, 641, 633, 635, 634, 636, 640, 642, 641, 644, 643, 637, 635, 636, 638, 644, 637, 639, 638, 93, 94, 93, 95, 94, 639, 96, 95, 97, 96, 98, 97, 99, 98, 100, 99, 101, 100, 102, 103, 101, 102, 104, 103, 105, 106, 104, 107, 105, 108, 106, 107, 109, 108, 110, 111, 109, 114, 110, 115, 111, 116, 114, 117, 115, 118, 116, 117, 119, 118, 120, 119, 121, 122, 120, 121, 125, 126, 122, 125, 127, 126, 128, 127, 129, 128, 130, 129, 131, 132, 130, 133, 131, 134, 132, 133, 135, 134, 136, 135, 137, 138, 136, 139, 137, 140, 138, 141, 139, 140, 142, 141, 145, 146, 142, 147, 145, 146, 148, 149, 147, 148, 152, 149, 153, 154, 152, 155, 153, 156, 154, 155, 158, 159, 156, 160, 158, 159, 161, 160, 162, 161, 163, 164, 162, 163, 165, 164, 166, 165, 167, 168, 166, 169, 167, 170, 168, 169, 171, 170, 172, 171, 173, 172, 174, 173, 175, 176, 174, 177, 175, 176, 178, 177, 179, 180, 178, 181, 179, 180, 182, 183, 181, 184, 182, 185, 183, 186, 184, 187, 185, 188, 186, 190, 187, 191, 188, 192, 190, 193, 191, 194, 192, 193, 195, 194, 196, 195, 197, 196, 198, 197, 199, 200, 198, 199, 201, 200, 202, 203, 201, 202, 204, 205, 203, 206, 204, 207, 205, 206, 208, 209, 207, 208, 210, 211, 209, 212, 210, 213, 211, 212, 214, 213, 215, 216, 214, 215, 217, 219, 216, 220, 217, 219, 221, 222, 220, 221, 223, 224, 222, 225, 223, 226, 224, 225, 227, 226, 228, 227, 229, 228, 230, 231, 229, 230, 232, 233, 231, 234, 232, 233, 235, 236, 234, 237, 235, 238, 236, 237, 239, 240, 238, 239, 241, 242, 240, 241, 243, 244, 242, 245, 243, 244, 246, 245, 247, 248, 246, 247, 249, 248, 250, 251, 249, 250, 252, 251, 253, 252, 254, 255, 253, 256, 254, 257, 255, 256, 258, 259, 257, 260, 258, 259, 261, 262, 260, 261, 263, 264, 262, 263, 265, 264, 266, 267, 265, 268, 266, 269, 267, 270, 268, 271, 269, 270, 272, 271, 273, 272, 274, 275, 273, 274, 276, 277, 275, 276, 278, 279, 277, 280, 278, 281, 279, 282, 280, 283, 281, 284, 282, 283, 285, 286, 284, 285, 287, 288, 286, 289, 287, 288, 290, 291, 289, 292, 290, 293, 291, 294, 292, 295, 293, 296, 294, 297, 295, 298, 296, 297, 299, 298, 645, 641, 299, 642, 641, 642, 644, 645, 644, 646, 646, 646, 646, 646, 646]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 5, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 3, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 0, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 3, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 3, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_GA, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 3, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR2\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR2, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 4, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR2\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR2, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 2, 'LFOH_GA': 2, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_TS, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 2, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_GA, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 3, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 6, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 3, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 1, 'CDR4': 7, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 5, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 3, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 2, 'CDR4': 7, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 3, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 2, 'CDR4': 7, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 3, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 2, 'CDR4': 8, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_GA, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 2, 'CDR4': 8, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 3, 'CDR4': 8, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 4, 'CDR4': 8, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 1, 'TS': 4, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 8, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [318, 192, 259, 631, 334, 24, 544, 101, 222, 207, 42, 15, 381, 173, 312, 121, 11, 261, 561, 200, 279, 234, 549, 544, 241, 11, 35, 141, 590, 68, 67, 15, 10, 40, 534, 76, 264, 134, 601, 528, 616, 580, 344, 161, 223, 40, 639, 13, 127, 117, 299, 276, 10, 414, 13, 496, 127, 167, 258, 325, 159, 11, 10, 543, 33, 580, 574, 82, 11, 102, 294, 19, 14, 560, 12, 368, 74, 16, 103, 47, 238, 12, 141, 90, 14, 601, 625, 136, 253, 13, 131, 595, 13, 79, 84, 109, 473, 197, 292, 122, 18, 109, 63, 289, 143, 14, 599, 181, 44, 573, 128, 14, 272, 142, 15, 216, 162, 66, 411, 210, 355, 20, 435, 142, 138, 197, 78, 187, 517, 171, 263, 500, 51, 98, 178, 37, 19, 277, 291, 215, 159, 60, 29, 472, 45, 501, 16, 209, 633, 269, 71, 342, 20, 172, 16, 70, 198, 75, 562, 132, 68, 25, 20, 316, 633, 77, 539, 195, 41, 167, 16, 96, 456, 445, 156, 65, 17, 22, 16, 167, 158, 513, 21, 137, 231, 539, 18, 17, 600, 335, 22, 18, 550, 80, 296, 179, 50, 95, 19, 597, 96, 188, 72, 514, 484, 105, 296, 525, 194, 23, 610, 229, 214, 616, 31, 29, 105, 240, 149, 114, 38, 19, 115, 447, 245, 524, 49, 19, 261, 114, 243, 337, 610, 586, 23, 67, 47, 251, 281, 614, 264, 143, 107, 553, 53, 286, 464, 385, 20, 397, 594, 541, 121, 275, 462, 167, 20, 64, 638, 24, 118, 37, 586, 23, 272, 21, 54, 552, 152, 23, 121, 25, 29, 22, 21, 140, 531, 629, 46, 143, 289, 535, 554, 25, 199, 210, 626, 154, 388, 39, 493, 501, 22, 27, 106, 24, 254, 80, 190, 606, 24, 166, 277, 517, 30, 226, 39, 634, 26, 548, 25, 199, 518, 626, 297, 432, 620, 25, 30, 74, 27, 595, 291, 26, 250, 225, 27, 440, 204, 358, 250, 636, 268, 242, 604, 241, 219, 45, 43, 30, 106, 26, 28, 270, 596, 108, 30, 26, 557, 621, 295, 28, 480, 427, 604, 632, 161, 59, 201, 589, 637, 120, 557, 114, 33, 475, 279, 209, 133, 379, 31, 566, 28, 186, 526, 632, 72, 279, 119, 339, 29, 31, 28, 148, 32, 72, 378, 171, 29, 34, 125, 575, 578, 117, 32, 526, 584, 168, 115, 34, 536, 31, 117, 146, 101, 135, 187, 292, 33, 31, 618, 181, 153, 33, 32, 61, 603, 584, 36, 257, 34, 32, 260, 164, 638, 470, 218, 35, 34, 88, 37, 236, 93, 151, 596, 38, 37, 576, 212, 271, 635, 603, 36, 40, 79, 35, 165, 502, 186, 40, 265, 38, 91, 625, 41, 181, 532, 577, 97, 91, 511, 41, 205, 600, 242, 36, 68, 500, 36, 144, 174, 48, 49, 538, 628, 588, 515, 246, 510, 511, 78, 42, 41, 93, 113, 109, 41, 208, 486, 232, 110, 42, 617, 263, 248, 82, 592, 43, 510, 471, 110, 137, 516, 167, 169, 292, 296, 264, 410, 42, 88, 294, 147, 42, 507, 572, 516, 512, 43, 73, 46, 63, 45, 328, 46, 52, 73, 284, 45, 261, 611, 512, 520, 52, 44, 58, 523, 513, 400, 44, 46, 213, 185, 58, 442, 51, 518, 200, 519, 520, 525, 190, 139, 95, 535, 559, 50, 44, 439, 92, 53, 578, 44, 250, 546, 519, 629, 573, 549, 65, 53, 259, 524, 46, 48, 50, 65, 56, 162, 47, 541, 50, 180, 208, 533, 543, 57, 55, 197, 546, 56, 63, 631, 54, 57, 273, 55, 51, 48, 270, 574, 556, 533, 48, 257, 54, 269, 60, 166, 61, 107, 144, 102, 84, 155, 59, 563, 51, 146, 630, 556, 52, 51, 490, 244, 562, 266, 69, 52, 142, 284, 503, 194, 142, 207, 69, 76, 197, 115, 205, 187, 571, 186, 62, 99, 503, 615, 396, 331, 141, 70, 140, 200, 62, 170, 53, 569, 118, 232, 53, 121, 227, 558, 220, 70, 196, 209, 91, 57, 54, 215, 476, 67, 60, 176, 78, 58, 76, 558, 567, 465, 131, 58, 159, 56, 79, 154, 176, 103, 54, 566, 56, 59, 509, 61, 55, 59, 85, 155, 66, 330, 77, 121, 225, 74, 55, 57, 619, 564, 567, 84, 171, 134, 591, 162, 571, 98, 225, 561, 83, 613, 67, 577, 221, 92, 565, 564, 68, 288, 588, 83, 170, 71, 68, 60, 103, 288, 485, 540, 60, 346, 274, 431, 71, 63, 275, 294, 565, 570, 85, 90, 62, 572, 430, 499, 100, 128, 62, 232, 599, 450, 81, 72, 576, 175, 71, 136, 100, 598, 570, 64, 72, 81, 146, 71, 408, 97, 618, 94, 141, 64, 115, 74, 111, 266, 592, 124, 65, 73, 216, 94, 611, 69, 104, 111, 184, 147, 598, 602, 621, 69, 76, 230, 75, 184, 253, 112, 630, 101, 448, 545, 76, 248, 235, 70, 78, 215, 65, 237, 84, 95, 73, 67, 169, 138, 607, 602, 79, 84, 177, 77, 70, 125, 635, 273, 276, 522, 75, 77, 220, 108, 622, 79, 289, 81, 126, 81, 83, 98, 122, 293, 522, 607, 582, 161, 96, 88, 83, 126, 217, 85, 99, 178, 104, 86, 152, 116, 507, 90, 85, 89, 133, 292, 90, 92, 89, 116, 119, 88, 108, 582, 609, 229, 154, 91, 86, 93, 92, 321, 454, 110, 261, 119, 211, 132, 113, 237, 93, 105, 95, 159, 107, 249, 120, 97, 609, 207, 95, 239, 94, 250, 98, 634, 120, 256, 94, 145, 284, 102, 137, 122, 98, 103, 636, 97, 100, 103, 104, 187, 228, 129, 593, 105, 104, 176, 100, 136, 125, 107, 115, 109, 111, 290, 129, 148, 110, 194, 133, 111, 213, 132, 106, 296, 140, 106, 130, 112, 149, 108, 579, 112, 256, 149, 135, 332, 113, 130, 191, 108, 235, 491, 114, 153, 145, 583, 134, 123, 135, 287, 116, 153, 168, 211, 117, 306, 116, 529, 253, 254, 148, 156, 201, 117, 138, 128, 297, 118, 361, 156, 131, 255, 164, 118, 119, 125, 179, 139, 120, 119, 172, 129, 164, 160, 123, 122, 120, 150, 183, 623, 125, 122, 124, 179, 192, 160, 191, 124, 151, 183, 188, 628, 293, 157, 220, 126, 173, 158, 131, 127, 130, 126, 249, 407, 569, 195, 173, 402, 627, 132, 127, 196, 185, 479, 540, 477, 273, 204, 182, 135, 180, 581, 168, 136, 192, 182, 206, 193, 128, 174, 134, 591, 269, 624, 416, 137, 206, 193, 212, 134, 299, 129, 136, 138, 619, 188, 140, 212, 219, 145, 138, 203, 287, 198, 612, 146, 150, 195, 145, 130, 176, 217, 390, 298, 530, 132, 226, 202, 133, 198, 271, 133, 505, 340, 214, 226, 219, 222, 481, 153, 137, 247, 221, 155, 135, 365, 214, 421, 551, 161, 223, 258, 225, 216, 233, 244, 262, 506, 223, 224, 177, 228, 147, 291, 231, 265, 147, 139, 158, 202, 241, 139, 165, 246, 231, 234, 280, 262, 243, 148, 175, 278, 149, 148, 236, 336, 162, 285, 151, 270, 149, 164, 150, 204, 240, 154, 236, 170, 234, 301, 274, 153, 290, 302, 154, 156, 168, 304, 155, 282, 158, 245, 305, 156, 157, 169, 307, 581, 309, 579, 610, 157, 313, 172, 323, 420, 245, 224, 258, 251, 317, 174, 240, 168, 319, 252, 329, 207, 170, 433, 163, 345, 251, 267, 179, 348, 160, 163, 349, 182, 353, 169, 256, 160, 375, 267, 373, 247, 259, 172, 185, 359, 281, 161, 268, 550, 364, 275, 179, 162, 382, 594, 366, 273, 164, 295, 367, 281, 372, 182, 165, 389, 173, 391, 201, 276, 188, 283, 286, 393, 254, 181, 173, 280, 399, 192, 174, 295, 446, 181, 183, 418, 175, 303, 419, 242, 260, 249, 286, 310, 422, 177, 188, 311, 423, 198, 190, 315, 424, 183, 428, 350, 199, 299, 265, 322, 193, 434, 185, 297, 457, 326, 239, 459, 333, 190, 193, 195, 460, 341, 205, 192, 467, 343, 196, 195, 474, 351, 198, 211, 352, 483, 199, 202, 196, 488, 356, 207, 627, 492, 357, 215, 615, 285, 203, 362, 497, 225, 369, 216, 370, 204, 220, 202, 371, 217, 216, 384, 206, 203, 387, 269, 392, 560, 206, 204, 394, 221, 401, 205, 403, 404, 211, 521, 405, 230, 415, 213, 417, 215, 212, 468, 425, 223, 239, 441, 212, 586, 444, 223, 227, 478, 482, 237, 227, 489, 214, 240, 219, 214, 245, 217, 222, 584, 232, 224, 219, 226, 224, 221, 590, 229, 228, 226, 222, 230, 612, 231, 231, 233, 252, 270, 233, 235, 253, 228, 234, 235, 254, 241, 234, 236, 255, 237, 243, 236, 259, 238, 240, 244, 262, 243, 242, 626, 265, 245, 244, 271, 292, 509, 280, 246, 282, 247, 246, 256, 285, 589, 247, 552, 257, 290, 249, 252, 291, 254, 251, 297, 255, 258, 251, 299, 259, 253, 258, 267, 537, 264, 265, 268, 267, 262, 266, 274, 268, 284, 639, 274, 275, 269, 587, 271, 298, 275, 280, 539, 547, 282, 278, 500, 279, 278, 279, 281, 604, 610, 283, 287, 283, 281, 285, 286, 501, 287, 286, 288, 291, 294, 288, 504, 290, 294, 605, 617, 593, 510, 297, 529, 295, 298, 295, 603, 299, 504, 639, 514, 506, 505, 534, 530, 516, 537, 500, 502, 515, 501, 508, 502, 532, 534, 511, 508, 554, 510, 511, 517, 521, 519, 604, 516, 512, 517, 515, 542, 512, 523, 535, 514, 513, 523, 548, 532, 513, 518, 528, 519, 518, 525, 531, 527, 553, 520, 527, 536, 545, 524, 520, 548, 555, 550, 526, 535, 524, 575, 538, 553, 525, 554, 541, 542, 536, 556, 538, 533, 526, 541, 556, 543, 528, 600, 539, 531, 544, 551, 546, 559, 544, 533, 562, 546, 552, 567, 560, 549, 562, 555, 573, 567, 543, 574, 549, 563, 561, 558, 574, 559, 578, 547, 614, 558, 568, 561, 566, 568, 595, 583, 625, 594, 566, 572, 590, 577, 597, 613, 564, 603, 606, 564, 565, 580, 584, 570, 565, 582, 586, 571, 585, 570, 599, 571, 595, 588, 573, 576, 572, 599, 592, 597, 576, 577, 608, 600, 598, 578, 588, 607, 608, 580, 609, 606, 616, 582, 592, 621, 585, 598, 602, 605, 618, 609, 602, 614, 611, 618, 620, 607, 625, 622, 611, 623, 620, 631, 616, 630, 624, 636, 631, 621, 632, 622, 636, 637, 633, 626, 632, 635, 630, 634, 637, 635, 633, 638, 634, 638, 640, 640]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 1, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 3, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 8, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_TS, Action counts: {'GA': 1, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 8, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 1, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 6, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 1, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 7, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 7, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 1, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 7, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 8, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: GA, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 7, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 8, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 8, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 8, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 1, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 8, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 2, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 8, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 5, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 8, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR2\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR2, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 8, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 4, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_GA, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 6, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR5, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 1, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 7, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAP_LFO\n",
      "Step reward: -0.014336805790662766, Total episode reward: -0.014336805790662766\n",
      "Action taken: LAP_LFO, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 7, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: -0.014336805790662766\n",
      "Action taken: CDR5, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 8, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: -0.014336805790662766\n",
      "Action taken: CDR5, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 9, 'LAPH_TS': 4, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 9, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-TS\n",
      "Step reward: -0.0, Total episode reward: -0.014336805790662766\n",
      "Action taken: LFOH_TS, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 4, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 9, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-TS\n",
      "Step reward: -0.0, Total episode reward: -0.014336805790662766\n",
      "Action taken: LAPH_TS, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 5, 'CDR4': 9, 'CDR5': 9, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: -0.014336805790662766\n",
      "Action taken: CDR3, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 6, 'CDR4': 9, 'CDR5': 9, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR5\n",
      "Step reward: -0.0, Total episode reward: -0.014336805790662766\n",
      "Action taken: CDR5, Action counts: {'GA': 2, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 6, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    GA\n",
      "Step reward: -0.0, Total episode reward: -0.014336805790662766\n",
      "Action taken: GA, Action counts: {'GA': 3, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 5, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 6, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 3}\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 11       |\n",
      "|    ep_rew_mean      | -0.0286  |\n",
      "|    exploration_rate | 0.3      |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 0        |\n",
      "|    time_elapsed     | 187      |\n",
      "|    total_timesteps  | 88       |\n",
      "| train/              |          |\n",
      "|    actual_tardiness | 0        |\n",
      "|    episode_reward   | 0        |\n",
      "----------------------------------\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH-GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH_GA, Action counts: {'GA': 3, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 6, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: GA, Action counts: {'GA': 4, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 6, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 4, 'TS': 5, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [589, 279, 597, 592, 588, 234, 231, 240, 253, 233, 594, 284, 240, 245, 236, 599, 597, 595, 592, 243, 292, 284, 245, 249, 596, 246, 247, 602, 598, 595, 295, 249, 254, 599, 252, 251, 297, 604, 254, 598, 259, 600, 256, 261, 318, 602, 259, 267, 319, 262, 322, 607, 603, 600, 265, 329, 264, 332, 605, 267, 270, 335, 268, 604, 339, 343, 610, 603, 606, 608, 348, 273, 275, 270, 352, 607, 271, 356, 358, 279, 361, 276, 364, 281, 615, 275, 606, 610, 609, 280, 367, 372, 375, 614, 379, 289, 286, 281, 384, 619, 611, 609, 288, 389, 392, 295, 286, 397, 294, 292, 403, 612, 405, 621, 619, 611, 417, 618, 294, 419, 296, 297, 422, 425, 615, 430, 432, 299, 296, 623, 618, 620, 439, 442, 446, 321, 621, 299, 454, 459, 326, 626, 622, 620, 331, 462, 333, 465, 624, 337, 470, 478, 341, 623, 481, 346, 351, 628, 483, 622, 625, 489, 355, 493, 626, 357, 499, 359, 362, 642, 366, 630, 627, 625, 371, 373, 378, 382, 628, 388, 632, 627, 629, 391, 394, 401, 404, 630, 410, 418, 634, 631, 629, 421, 424, 428, 431, 632, 433, 636, 633, 631, 440, 445, 448, 457, 634, 460, 464, 638, 635, 633, 467, 475, 479, 636, 482, 485, 20, 635, 637, 490, 496, 23, 641, 638, 25, 639, 637, 27, 29, 20, 22, 31, 639, 24, 33, 22, 23, 25, 26, 24, 35, 27, 26, 28, 37, 29, 28, 30, 41, 31, 30, 32, 43, 33, 45, 32, 34, 35, 34, 47, 36, 38, 37, 40, 36, 50, 41, 42, 40, 52, 43, 42, 44, 54, 45, 56, 44, 46, 47, 46, 48, 58, 50, 48, 60, 51, 52, 53, 62, 51, 54, 53, 65, 55, 56, 55, 68, 57, 58, 57, 59, 70, 60, 61, 72, 59, 62, 63, 61, 74, 65, 64, 76, 63, 67, 68, 78, 67, 69, 70, 69, 80, 71, 72, 71, 83, 73, 74, 75, 73, 85, 76, 75, 89, 77, 78, 79, 77, 91, 80, 79, 93, 81, 83, 81, 95, 84, 85, 84, 97, 88, 89, 100, 90, 88, 91, 103, 90, 92, 93, 105, 94, 92, 95, 94, 107, 96, 97, 109, 98, 96, 101, 100, 111, 102, 98, 103, 102, 104, 113, 105, 115, 104, 106, 107, 117, 108, 106, 109, 119, 108, 110, 111, 121, 112, 110, 113, 114, 112, 124, 115, 116, 114, 126, 117, 118, 116, 128, 119, 118, 130, 120, 121, 122, 132, 120, 124, 123, 125, 122, 135, 126, 125, 137, 127, 128, 127, 129, 139, 130, 129, 131, 141, 133, 132, 131, 134, 143, 135, 136, 134, 146, 137, 138, 136, 148, 139, 138, 153, 140, 141, 142, 140, 155, 143, 144, 157, 142, 146, 145, 144, 147, 160, 148, 162, 149, 147, 152, 150, 149, 165, 154, 155, 153, 167, 156, 154, 157, 169, 158, 156, 160, 159, 161, 172, 158, 163, 162, 161, 174, 164, 165, 166, 176, 164, 167, 179, 168, 166, 170, 169, 171, 181, 168, 172, 171, 173, 183, 174, 185, 175, 173, 176, 177, 187, 175, 179, 178, 180, 190, 177, 181, 180, 194, 182, 183, 196, 184, 182, 185, 198, 184, 186, 187, 188, 186, 200, 191, 190, 192, 203, 188, 194, 193, 205, 192, 195, 196, 195, 197, 207, 198, 197, 209, 199, 200, 201, 212, 199, 203, 202, 204, 201, 214, 205, 204, 206, 216, 207, 206, 219, 208, 210, 209, 211, 221, 208, 212, 211, 213, 223, 214, 215, 213, 225, 216, 217, 227, 215, 219, 217, 229, 220, 221, 231, 220, 222, 223, 222, 224, 233, 225, 235, 224, 226, 227, 228, 237, 226, 229, 230, 228, 240, 231, 230, 242, 232, 233, 232, 234, 244, 235, 234, 236, 246, 238, 237, 249, 236, 239, 240, 241, 251, 239, 242, 253, 241, 243, 244, 243, 245, 255, 246, 247, 245, 257, 249, 248, 247, 250, 259, 251, 261, 252, 250, 253, 252, 254, 264, 255, 254, 256, 267, 257, 256, 258, 269, 259, 258, 260, 271, 261, 262, 275, 260, 264, 263, 262, 278, 265, 267, 266, 268, 265, 280, 269, 268, 270, 282, 271, 273, 284, 270, 275, 274, 273, 276, 286, 278, 277, 288, 279, 276, 280, 279, 281, 290, 282, 292, 281, 283, 284, 285, 283, 294, 286, 296, 285, 287, 288, 289, 298, 287, 290, 289, 291, 292, 293, 291, 294, 293, 295, 296, 295, 297, 298, 297, 299, 299, 643, 643, 643, 643, 643, 643]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 4, 'TS': 6, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 3}\n",
      "-------------------------------------------------\n",
      "Method selection:                    RCRS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: RCRS, Action counts: {'GA': 4, 'TS': 6, 'LFOH': 3, 'LAPH': 6, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH, Action counts: {'GA': 4, 'TS': 6, 'LFOH': 3, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [277, 38, 630, 57, 58, 46, 47, 59, 60, 48, 51, 50, 62, 63, 52, 54, 53, 65, 67, 55, 57, 56, 58, 59, 60, 61, 68, 62, 65, 63, 71, 72, 67, 68, 61, 74, 75, 71, 72, 77, 74, 78, 75, 77, 76, 78, 79, 76, 81, 83, 79, 81, 80, 83, 84, 80, 88, 89, 84, 85, 88, 90, 89, 85, 92, 90, 93, 92, 91, 93, 94, 91, 96, 94, 97, 95, 96, 97, 98, 95, 102, 103, 98, 100, 102, 104, 103, 106, 100, 107, 104, 106, 105, 108, 107, 110, 105, 111, 108, 110, 109, 111, 112, 109, 114, 112, 115, 113, 114, 116, 115, 118, 113, 119, 116, 118, 117, 120, 119, 117, 122, 120, 124, 121, 122, 124, 125, 121, 127, 125, 128, 127, 126, 129, 128, 126, 131, 129, 132, 130, 131, 132, 134, 130, 136, 137, 134, 136, 135, 137, 138, 135, 140, 141, 138, 139, 140, 141, 142, 139, 144, 146, 142, 144, 143, 146, 147, 143, 149, 153, 147, 148, 149, 154, 153, 156, 148, 157, 154, 155, 156, 158, 157, 155, 161, 158, 162, 161, 160, 162, 164, 166, 160, 167, 164, 166, 165, 167, 168, 171, 165, 172, 168, 169, 171, 173, 172, 175, 169, 176, 173, 174, 175, 177, 176, 180, 174, 177, 181, 179, 180, 182, 181, 179, 184, 182, 185, 184, 183, 185, 186, 188, 183, 190, 186, 187, 188, 192, 190, 195, 187, 192, 196, 194, 195, 196, 197, 199, 194, 197, 200, 198, 199, 200, 201, 198, 204, 201, 205, 203, 204, 206, 205, 203, 208, 209, 206, 208, 207, 209, 211, 213, 207, 211, 214, 212, 213, 215, 214, 217, 212, 219, 215, 216, 217, 220, 219, 216, 222, 220, 223, 221, 222, 223, 224, 226, 221, 224, 227, 225, 226, 227, 228, 230, 225, 231, 228, 229, 230, 231, 232, 234, 229, 235, 232, 234, 233, 235, 236, 239, 233, 240, 236, 239, 237, 240, 241, 243, 237, 244, 241, 242, 243, 244, 245, 242, 247, 245, 249, 246, 247, 249, 250, 252, 246, 250, 253, 251, 252, 253, 254, 256, 251, 257, 254, 255, 256, 257, 258, 255, 260, 261, 258, 260, 259, 262, 261, 259, 265, 262, 267, 264, 265, 268, 267, 270, 264, 271, 268, 270, 269, 271, 273, 276, 269, 273, 278, 275, 276, 278, 279, 275, 281, 279, 282, 280, 281, 283, 282, 280, 285, 283, 286, 285, 284, 287, 286, 289, 284, 287, 290, 289, 288, 290, 291, 293, 288, 291, 294, 292, 293, 294, 295, 297, 292, 298, 295, 297, 296, 299, 298, 296, 73, 20, 299, 73, 70, 20, 69, 70, 22, 23, 69, 24, 22, 23, 25, 24, 26, 25, 27, 26, 28, 29, 27, 30, 28, 31, 29, 30, 32, 33, 31, 32, 34, 35, 33, 36, 34, 37, 35, 40, 36, 41, 37, 40, 42, 43, 41, 631, 42, 43, 633, 634, 631, 633, 635, 634, 636, 635, 637, 636, 638, 637, 639, 638, 643, 639, 643, 646, 646, 646, 646, 646]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 4, 'TS': 7, 'LFOH': 3, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    TS\n",
      "check OA [84, 83, 88, 104, 94, 88, 89, 110, 89, 85, 111, 92, 85, 109, 90, 92, 91, 112, 96, 91, 97, 115, 98, 97, 102, 113, 95, 102, 103, 116, 103, 100, 119, 100, 106, 122, 104, 107, 106, 121, 107, 105, 125, 112, 108, 105, 126, 110, 114, 108, 132, 111, 109, 118, 114, 130, 115, 113, 117, 136, 116, 120, 117, 135, 118, 120, 124, 119, 138, 122, 121, 124, 127, 139, 125, 128, 127, 142, 126, 129, 128, 144, 130, 129, 131, 146, 132, 134, 131, 143, 136, 137, 134, 149, 135, 140, 137, 153, 144, 138, 140, 141, 148, 142, 141, 147, 156, 148, 143, 139, 154, 155, 153, 146, 157, 160, 156, 147, 158, 157, 166, 149, 155, 161, 158, 171, 154, 166, 162, 161, 169, 160, 162, 164, 175, 164, 167, 174, 167, 165, 180, 171, 165, 168, 181, 168, 172, 184, 169, 172, 173, 183, 175, 173, 176, 187, 180, 174, 177, 176, 195, 181, 177, 179, 196, 182, 179, 197, 184, 182, 185, 199, 183, 186, 185, 198, 186, 188, 201, 187, 188, 190, 204, 190, 192, 203, 197, 192, 194, 209, 195, 200, 194, 213, 196, 199, 200, 205, 217, 201, 204, 198, 206, 216, 203, 205, 208, 226, 206, 209, 208, 207, 228, 207, 211, 229, 213, 211, 214, 239, 214, 212, 237, 217, 212, 215, 242, 215, 219, 247, 216, 220, 219, 252, 220, 222, 254, 223, 222, 255, 223, 221, 260, 226, 224, 221, 261, 227, 224, 265, 227, 225, 264, 225, 230, 270, 228, 230, 231, 269, 229, 232, 231, 278, 232, 234, 279, 234, 235, 281, 233, 235, 280, 233, 236, 284, 239, 240, 236, 289, 240, 241, 290, 237, 241, 243, 288, 242, 244, 243, 293, 247, 244, 245, 295, 252, 245, 249, 296, 254, 246, 249, 73, 255, 261, 246, 250, 20, 265, 253, 250, 26, 251, 253, 27, 251, 256, 30, 257, 256, 31, 260, 257, 258, 32, 258, 259, 37, 259, 262, 43, 262, 267, 633, 264, 268, 267, 269, 271, 268, 635, 270, 273, 271, 278, 273, 276, 279, 276, 275, 637, 280, 275, 282, 281, 283, 639, 282, 285, 283, 284, 285, 286, 288, 646, 286, 287, 293, 289, 287, 291, 290, 291, 294, 294, 292, 295, 297, 292, 297, 298, 296, 299, 298, 73, 299, 70, 53, 20, 69, 70, 22, 69, 23, 22, 30, 23, 24, 25, 24, 28, 25, 26, 29, 27, 33, 29, 28, 31, 34, 32, 35, 34, 33, 43, 35, 36, 37, 40, 36, 41, 40, 41, 42, 631, 42, 633, 631, 634, 635, 634, 636, 637, 636, 638, 639, 643, 638, 646, 643, 647, 647, 647, 647, 647]\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: TS, Action counts: {'GA': 4, 'TS': 8, 'LFOH': 3, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH, Action counts: {'GA': 4, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: GA, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 9, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 10, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 7, 'CDR4': 9, 'CDR5': 10, 'CDR6': 11, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 8, 'CDR4': 9, 'CDR5': 10, 'CDR6': 11, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR6\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR6, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 5, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 8, 'CDR4': 9, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LAPH-TS\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LAPH_TS, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 6, 'CDR3': 8, 'CDR4': 9, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR2\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR2, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 7, 'CDR3': 8, 'CDR4': 9, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 4, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 7, 'CDR3': 8, 'CDR4': 10, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    LFOH\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: LFOH, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 5, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 7, 'CDR3': 8, 'CDR4': 10, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 5, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 7, 'CDR3': 8, 'CDR4': 11, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR3\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR3, Action counts: {'GA': 5, 'TS': 8, 'LFOH': 5, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 7, 'CDR3': 9, 'CDR4': 11, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    GA\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: GA, Action counts: {'GA': 6, 'TS': 8, 'LFOH': 5, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 7, 'CDR3': 9, 'CDR4': 11, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n",
      "-------------------------------------------------\n",
      "Method selection:                    CDR4\n",
      "Step reward: -0.0, Total episode reward: 0.0\n",
      "Action taken: CDR4, Action counts: {'GA': 6, 'TS': 8, 'LFOH': 5, 'LAPH': 7, 'LAP_LFO': 2, 'LFOH_TS': 10, 'LAPH_TS': 6, 'LFOH_GA': 6, 'LAPH_GA': 4, 'CDR1': 2, 'CDR2': 7, 'CDR3': 9, 'CDR4': 12, 'CDR5': 10, 'CDR6': 12, 'RCRS': 4}\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "action_list            = [\"GA\", \"TS\", \n",
    "                          \"LFOH\", \"LAPH\", \"LAP_LFO\", \n",
    "                          \"LFOH_TS\", \"LAPH_TS\", \"LFOH_GA\", \"LAPH_GA\",\n",
    "                          \"CDR1\", \"CDR2\", \"CDR3\", \"CDR4\", \"CDR5\", \"CDR6\",\n",
    "                          \"RCRS\"]\n",
    "                          \n",
    "# Create directories for models and logs\n",
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "models_dir = f\"models/DQN-{current_time}\"\n",
    "logdir = f\"logs/DQN-{current_time}\"\n",
    "log_training_txt_dir = \"log_training_txt\"\n",
    "log_training_excel_dir = \"log_training_excel\"\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(logdir):\n",
    "    os.makedirs(logdir)\n",
    "if not os.path.exists(log_training_txt_dir):\n",
    "    os.makedirs(log_training_txt_dir)\n",
    "if not os.path.exists(log_training_excel_dir):\n",
    "    os.makedirs(log_training_excel_dir)\n",
    "\n",
    "# Generate unique file names based on current time\n",
    "log_file          = os.path.join(log_training_txt_dir,   f\"training_{current_time}.txt\")\n",
    "excel_file        = os.path.join(log_training_excel_dir, f\"training_{current_time}.xlsx\")\n",
    "action_count_file = os.path.join(log_training_txt_dir,   f\"action_count_{current_time}.txt\")\n",
    "action_excel_file = os.path.join(log_training_excel_dir, f\"action_count_{current_time}.xlsx\")\n",
    "\n",
    "# Define the custom callback -------------------------------------------------------------\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, log_dir, excel_file, txt_file, action_count_file, action_excel_file, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.log_dir = log_dir\n",
    "        self.excel_file = excel_file\n",
    "        self.txt_file = txt_file\n",
    "        self.action_count_file = action_count_file\n",
    "        self.action_excel_file = action_excel_file\n",
    "        self.logs = []\n",
    "        self.episode_rewards = []\n",
    "        self.action_counts = {}\n",
    "        self.episode_start = True\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        # Initialize action counts\n",
    "        self.action_counts = {action: 0 for action in action_list}\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.episode_start:\n",
    "            self.episode_rewards.append(0)\n",
    "            self.episode_start = False\n",
    "\n",
    "        # Record reward for the current step\n",
    "        reward = self.locals['rewards'][0]\n",
    "        self.episode_rewards[-1] += reward\n",
    "\n",
    "        # Increment action count\n",
    "        action = self.locals.get('actions', None)\n",
    "        if action is not None:\n",
    "            action_name = action_list[action[0]]\n",
    "            self.action_counts[action_name] += 1\n",
    "        \n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        # Called at the end of each episode\n",
    "        sum_reward   = self.episode_rewards[-1] if self.episode_rewards else 0\n",
    "        tardiness    = self.training_env.get_attr('unwrapped')[0].all_Tard\n",
    "        \n",
    "        self.logger.record('train/episode_reward',   sum_reward)\n",
    "        self.logger.record('train/actual_tardiness', tardiness)\n",
    "        \n",
    "\n",
    "        self.logs.append({\n",
    "            'episode': len(self.episode_rewards),\n",
    "            'sum_reward': sum_reward,\n",
    "            'tardiness': tardiness\n",
    "        })\n",
    "\n",
    "        self.episode_start = True\n",
    "\n",
    "    \n",
    "    def _on_training_end(self) -> None:\n",
    "        # Save logs to Excel\n",
    "        df = pd.DataFrame(self.logs)\n",
    "        df.to_excel(self.excel_file, index=False)\n",
    "\n",
    "        action_df = pd.DataFrame(list(self.action_counts.items()), columns=['Action', 'Count'])\n",
    "        action_df.to_excel(self.action_excel_file, index=False)\n",
    "\n",
    "        # Save logs to text file\n",
    "        with open(self.txt_file, 'w') as f:\n",
    "            f.write(df.to_string(index=False))\n",
    "        with open(self.action_count_file, 'w') as f:\n",
    "            f.write(action_df.to_string(index=False))\n",
    "\n",
    "# Create the callback\n",
    "callback = CustomCallback(log_dir=logdir, \n",
    "                          excel_file=excel_file,\n",
    "                          txt_file=log_file,\n",
    "                          action_count_file=action_count_file,\n",
    "                          action_excel_file=action_excel_file,\n",
    "                          verbose=1)\n",
    "\n",
    "# Initialize the DQN model\n",
    "model_path = os.path.join(models_dir, f\"DQN_.zip\")\n",
    "model_phase1 = DQN(\"MlpPolicy\", \n",
    "                    env1, \n",
    "                    verbose=1, \n",
    "                    tensorboard_log=logdir, \n",
    "                    train_freq=(1,\"episode\"),\n",
    "                    exploration_initial_eps =1.00, \n",
    "                    exploration_final_eps   =0.30, \n",
    "                    exploration_fraction    =0.80,     \n",
    "                    target_update_interval  =2000\n",
    "                    )\n",
    "\n",
    "# Phase 1 training\n",
    "model_phase1.learn(total_timesteps=100, \n",
    "                    reset_num_timesteps=False, \n",
    "                    tb_log_name=\"DQN_phase1\",\n",
    "                    callback=callback\n",
    "                    )\n",
    "model_phase1.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FJSP_under_uncertainties_Env' object has no attribute 'list_scenario'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model_phase2\u001b[38;5;241m.\u001b[39mexploration_final_eps      \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.10\u001b[39m    \n\u001b[0;32m      5\u001b[0m model_phase2\u001b[38;5;241m.\u001b[39mexploration_fraction       \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.50\u001b[39m \n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel_phase2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDQN_phase2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m model_phase2\u001b[38;5;241m.\u001b[39msave(model_path)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\miniconda3\\envs\\dunnbebes\\lib\\site-packages\\stable_baselines3\\dqn\\dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[0;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[1;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\miniconda3\\envs\\dunnbebes\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:314\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfOffPolicyAlgorithm,\n\u001b[0;32m    307\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    313\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfOffPolicyAlgorithm:\n\u001b[1;32m--> 314\u001b[0m     total_timesteps, callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must set the environment before calling learn()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\miniconda3\\envs\\dunnbebes\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:297\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, VectorizedActionNoise)\n\u001b[0;32m    294\u001b[0m ):\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise \u001b[38;5;241m=\u001b[39m VectorizedActionNoise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_noise, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\miniconda3\\envs\\dunnbebes\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:423\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[1;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_num_timesteps \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\miniconda3\\envs\\dunnbebes\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:77\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m     76\u001b[0m     maybe_options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx]} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options[env_idx] \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m---> 77\u001b[0m     obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds[env_idx], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmaybe_options)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_obs(env_idx, obs)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Seeds and options are only used once\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\miniconda3\\envs\\dunnbebes\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:83\u001b[0m, in \u001b[0;36mMonitor.reset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected you to pass keyword argument \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m into reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_reset_info[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\D\\University\\4th year\\Thesis\\Hopefully\\Thesis\\env_action\\environment.py:228\u001b[0m, in \u001b[0;36mFJSP_under_uncertainties_Env.reset\u001b[1;34m(self, seed)\u001b[0m\n\u001b[0;32m    226\u001b[0m \t\t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_scenario(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fixed_scenario\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    227\u001b[0m \t\u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 228\u001b[0m \t\t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_scenario(random\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_scenario\u001b[49m))\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_scenario_per_instance \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FJSP_under_uncertainties_Env' object has no attribute 'list_scenario'"
     ]
    }
   ],
   "source": [
    "# Phase 2 training\n",
    "model_phase2 = DQN.load(model_path, env=env2)\n",
    "model_phase2.exploration_initial_eps    = 0.50  \n",
    "model_phase2.exploration_final_eps      = 0.10    \n",
    "model_phase2.exploration_fraction       = 0.50 \n",
    "model_phase2.learn(total_timesteps=150, tb_log_name=\"DQN_phase2\")\n",
    "model_phase2.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3 training\n",
    "model_phase3 = DQN.load(model_path, env=env3)\n",
    "model_phase3.exploration_initial_eps    = 0.20    \n",
    "model_phase3.exploration_final_eps      = 0.02    \n",
    "model_phase3.exploration_fraction       = 0.3 \n",
    "model_phase3.learn(total_timesteps=230, tb_log_name=\"DQN_phase3\")\n",
    "model_phase3.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dunnbebes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
